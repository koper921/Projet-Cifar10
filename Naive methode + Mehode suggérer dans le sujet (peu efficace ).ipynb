{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "#from scipy.misc import imread\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import mode\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f,encoding='latin1')\n",
    "    X = datadict['data']\n",
    "    \n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"double\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)    \n",
    "  Xtr = np.concatenate(xs)\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "#Normalise la base - la moyenne , divise par std, resultat final toujours mauvais normalisÃ© ou non\n",
    "#Normalize the data, by soustracting the mean and dividing the standart deviation \n",
    "  mean_image = np.mean(Xtr, axis=0)\n",
    "  std_image=np.std(Xtr, axis=0)\n",
    "  #Xtr -= mean_image\n",
    "  #Xtr /= std_image\n",
    "  \n",
    "  #Xte -= mean_image\n",
    "  #Xte /= std_image\n",
    "  return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    cifar10_dir = 'C:/Users/MyPC/Desktop/Projet Apprentissage Image/cifar-10-batches-py/'\n",
    "    \n",
    "    print (len(load_CIFAR10(cifar10_dir)))\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_train=X_train.swapaxes(1,3)\n",
    "    X_val=X_val.swapaxes(1,3)\n",
    "    X_test=X_test.swapaxes(1,3)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test=get_CIFAR10_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appliquer directement des classifieurs sur \n",
    "XtrainBis= np.zeros((len(X_train),3072))\n",
    "for i in range(0,len(X_train)):\n",
    "    XtrainBis[i,:]=X_train[i,:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(XtrainBis, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtestBis= np.zeros((len(X_test),3072))\n",
    "for i in range(0,len(X_test)):\n",
    "    XtestBis[i,:]=X_test[i,:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= neigh.predict(XtestBis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.327"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.327"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(XtrainBis, y_train)\n",
    "y_pred1= neigh.predict(XtestBis)\n",
    "(y_pred1==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(XtrainBis)\n",
    "kmeans.labels_\n",
    "\n",
    "y_pred2=kmeans.predict(XtestBis)\n",
    "(y_pred2==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Confusion matrix, without normalization\n",
      "[[52  1 12  1  5  0  5  3 23  1]\n",
      " [20 29 10  9  8  1  1  0 10  1]\n",
      " [18  0 40 10 17  6  5  1  3  0]\n",
      " [ 4  2 24 32 16  8 11  2  3  1]\n",
      " [10  0 17  5 39  5  7  2  5  0]\n",
      " [ 6  1 25 16 16 15  4  1  2  0]\n",
      " [ 7  1 35  7 37  1 22  1  1  0]\n",
      " [11  3 27  7 25  6  3 16  3  1]\n",
      " [18  5  2  4  6  1  0  1 69  0]\n",
      " [20  6 14  9 17  3  2  1 24 13]]\n",
      "Normalized confusion matrix\n",
      "[[0.5  0.01 0.12 0.01 0.05 0.   0.05 0.03 0.22 0.01]\n",
      " [0.22 0.33 0.11 0.1  0.09 0.01 0.01 0.   0.11 0.01]\n",
      " [0.18 0.   0.4  0.1  0.17 0.06 0.05 0.01 0.03 0.  ]\n",
      " [0.04 0.02 0.23 0.31 0.16 0.08 0.11 0.02 0.03 0.01]\n",
      " [0.11 0.   0.19 0.06 0.43 0.06 0.08 0.02 0.06 0.  ]\n",
      " [0.07 0.01 0.29 0.19 0.19 0.17 0.05 0.01 0.02 0.  ]\n",
      " [0.06 0.01 0.31 0.06 0.33 0.01 0.2  0.01 0.01 0.  ]\n",
      " [0.11 0.03 0.26 0.07 0.25 0.06 0.03 0.16 0.03 0.01]\n",
      " [0.17 0.05 0.02 0.04 0.06 0.01 0.   0.01 0.65 0.  ]\n",
      " [0.18 0.06 0.13 0.08 0.16 0.03 0.02 0.01 0.22 0.12]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "%matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test = y_test\n",
    "y_pred=y_pred1 \n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['airplane', 'automobile', 'bird', 'cat', 'deer' ,'dog', 'frog', 'horse' ,'ship' ,'truck'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['airplane', 'automobile', 'bird', 'cat', 'deer' ,'dog', 'frog', 'horse' ,'ship' ,'truck'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction patche: 0 / 200000\n",
      "Extraction patche: 1000 / 200000\n",
      "Extraction patche: 2000 / 200000\n",
      "Extraction patche: 3000 / 200000\n",
      "Extraction patche: 4000 / 200000\n",
      "Extraction patche: 5000 / 200000\n",
      "Extraction patche: 6000 / 200000\n",
      "Extraction patche: 7000 / 200000\n",
      "Extraction patche: 8000 / 200000\n",
      "Extraction patche: 9000 / 200000\n",
      "Extraction patche: 10000 / 200000\n",
      "Extraction patche: 11000 / 200000\n",
      "Extraction patche: 12000 / 200000\n",
      "Extraction patche: 13000 / 200000\n",
      "Extraction patche: 14000 / 200000\n",
      "Extraction patche: 15000 / 200000\n",
      "Extraction patche: 16000 / 200000\n",
      "Extraction patche: 17000 / 200000\n",
      "Extraction patche: 18000 / 200000\n",
      "Extraction patche: 19000 / 200000\n",
      "Extraction patche: 20000 / 200000\n",
      "Extraction patche: 21000 / 200000\n",
      "Extraction patche: 22000 / 200000\n",
      "Extraction patche: 23000 / 200000\n",
      "Extraction patche: 24000 / 200000\n",
      "Extraction patche: 25000 / 200000\n",
      "Extraction patche: 26000 / 200000\n",
      "Extraction patche: 27000 / 200000\n",
      "Extraction patche: 28000 / 200000\n",
      "Extraction patche: 29000 / 200000\n",
      "Extraction patche: 30000 / 200000\n",
      "Extraction patche: 31000 / 200000\n",
      "Extraction patche: 32000 / 200000\n",
      "Extraction patche: 33000 / 200000\n",
      "Extraction patche: 34000 / 200000\n",
      "Extraction patche: 35000 / 200000\n",
      "Extraction patche: 36000 / 200000\n",
      "Extraction patche: 37000 / 200000\n",
      "Extraction patche: 38000 / 200000\n",
      "Extraction patche: 39000 / 200000\n",
      "Extraction patche: 40000 / 200000\n",
      "Extraction patche: 41000 / 200000\n",
      "Extraction patche: 42000 / 200000\n",
      "Extraction patche: 43000 / 200000\n",
      "Extraction patche: 44000 / 200000\n",
      "Extraction patche: 45000 / 200000\n",
      "Extraction patche: 46000 / 200000\n",
      "Extraction patche: 47000 / 200000\n",
      "Extraction patche: 48000 / 200000\n",
      "Extraction patche: 49000 / 200000\n",
      "Extraction patche: 50000 / 200000\n",
      "Extraction patche: 51000 / 200000\n",
      "Extraction patche: 52000 / 200000\n",
      "Extraction patche: 53000 / 200000\n",
      "Extraction patche: 54000 / 200000\n",
      "Extraction patche: 55000 / 200000\n",
      "Extraction patche: 56000 / 200000\n",
      "Extraction patche: 57000 / 200000\n",
      "Extraction patche: 58000 / 200000\n",
      "Extraction patche: 59000 / 200000\n",
      "Extraction patche: 60000 / 200000\n",
      "Extraction patche: 61000 / 200000\n",
      "Extraction patche: 62000 / 200000\n",
      "Extraction patche: 63000 / 200000\n",
      "Extraction patche: 64000 / 200000\n",
      "Extraction patche: 65000 / 200000\n",
      "Extraction patche: 66000 / 200000\n",
      "Extraction patche: 67000 / 200000\n",
      "Extraction patche: 68000 / 200000\n",
      "Extraction patche: 69000 / 200000\n",
      "Extraction patche: 70000 / 200000\n",
      "Extraction patche: 71000 / 200000\n",
      "Extraction patche: 72000 / 200000\n",
      "Extraction patche: 73000 / 200000\n",
      "Extraction patche: 74000 / 200000\n",
      "Extraction patche: 75000 / 200000\n",
      "Extraction patche: 76000 / 200000\n",
      "Extraction patche: 77000 / 200000\n",
      "Extraction patche: 78000 / 200000\n",
      "Extraction patche: 79000 / 200000\n",
      "Extraction patche: 80000 / 200000\n",
      "Extraction patche: 81000 / 200000\n",
      "Extraction patche: 82000 / 200000\n",
      "Extraction patche: 83000 / 200000\n",
      "Extraction patche: 84000 / 200000\n",
      "Extraction patche: 85000 / 200000\n",
      "Extraction patche: 86000 / 200000\n",
      "Extraction patche: 87000 / 200000\n",
      "Extraction patche: 88000 / 200000\n",
      "Extraction patche: 89000 / 200000\n",
      "Extraction patche: 90000 / 200000\n",
      "Extraction patche: 91000 / 200000\n",
      "Extraction patche: 92000 / 200000\n",
      "Extraction patche: 93000 / 200000\n",
      "Extraction patche: 94000 / 200000\n",
      "Extraction patche: 95000 / 200000\n",
      "Extraction patche: 96000 / 200000\n",
      "Extraction patche: 97000 / 200000\n",
      "Extraction patche: 98000 / 200000\n",
      "Extraction patche: 99000 / 200000\n",
      "Extraction patche: 100000 / 200000\n",
      "Extraction patche: 101000 / 200000\n",
      "Extraction patche: 102000 / 200000\n",
      "Extraction patche: 103000 / 200000\n",
      "Extraction patche: 104000 / 200000\n",
      "Extraction patche: 105000 / 200000\n",
      "Extraction patche: 106000 / 200000\n",
      "Extraction patche: 107000 / 200000\n",
      "Extraction patche: 108000 / 200000\n",
      "Extraction patche: 109000 / 200000\n",
      "Extraction patche: 110000 / 200000\n",
      "Extraction patche: 111000 / 200000\n",
      "Extraction patche: 112000 / 200000\n",
      "Extraction patche: 113000 / 200000\n",
      "Extraction patche: 114000 / 200000\n",
      "Extraction patche: 115000 / 200000\n",
      "Extraction patche: 116000 / 200000\n",
      "Extraction patche: 117000 / 200000\n",
      "Extraction patche: 118000 / 200000\n",
      "Extraction patche: 119000 / 200000\n",
      "Extraction patche: 120000 / 200000\n",
      "Extraction patche: 121000 / 200000\n",
      "Extraction patche: 122000 / 200000\n",
      "Extraction patche: 123000 / 200000\n",
      "Extraction patche: 124000 / 200000\n",
      "Extraction patche: 125000 / 200000\n",
      "Extraction patche: 126000 / 200000\n",
      "Extraction patche: 127000 / 200000\n",
      "Extraction patche: 128000 / 200000\n",
      "Extraction patche: 129000 / 200000\n",
      "Extraction patche: 130000 / 200000\n",
      "Extraction patche: 131000 / 200000\n",
      "Extraction patche: 132000 / 200000\n",
      "Extraction patche: 133000 / 200000\n",
      "Extraction patche: 134000 / 200000\n",
      "Extraction patche: 135000 / 200000\n",
      "Extraction patche: 136000 / 200000\n",
      "Extraction patche: 137000 / 200000\n",
      "Extraction patche: 138000 / 200000\n",
      "Extraction patche: 139000 / 200000\n",
      "Extraction patche: 140000 / 200000\n",
      "Extraction patche: 141000 / 200000\n",
      "Extraction patche: 142000 / 200000\n",
      "Extraction patche: 143000 / 200000\n",
      "Extraction patche: 144000 / 200000\n",
      "Extraction patche: 145000 / 200000\n",
      "Extraction patche: 146000 / 200000\n",
      "Extraction patche: 147000 / 200000\n",
      "Extraction patche: 148000 / 200000\n",
      "Extraction patche: 149000 / 200000\n",
      "Extraction patche: 150000 / 200000\n",
      "Extraction patche: 151000 / 200000\n",
      "Extraction patche: 152000 / 200000\n",
      "Extraction patche: 153000 / 200000\n",
      "Extraction patche: 154000 / 200000\n",
      "Extraction patche: 155000 / 200000\n",
      "Extraction patche: 156000 / 200000\n",
      "Extraction patche: 157000 / 200000\n",
      "Extraction patche: 158000 / 200000\n",
      "Extraction patche: 159000 / 200000\n",
      "Extraction patche: 160000 / 200000\n",
      "Extraction patche: 161000 / 200000\n",
      "Extraction patche: 162000 / 200000\n",
      "Extraction patche: 163000 / 200000\n",
      "Extraction patche: 164000 / 200000\n",
      "Extraction patche: 165000 / 200000\n",
      "Extraction patche: 166000 / 200000\n",
      "Extraction patche: 167000 / 200000\n",
      "Extraction patche: 168000 / 200000\n",
      "Extraction patche: 169000 / 200000\n",
      "Extraction patche: 170000 / 200000\n",
      "Extraction patche: 171000 / 200000\n",
      "Extraction patche: 172000 / 200000\n",
      "Extraction patche: 173000 / 200000\n",
      "Extraction patche: 174000 / 200000\n",
      "Extraction patche: 175000 / 200000\n",
      "Extraction patche: 176000 / 200000\n",
      "Extraction patche: 177000 / 200000\n",
      "Extraction patche: 178000 / 200000\n",
      "Extraction patche: 179000 / 200000\n",
      "Extraction patche: 180000 / 200000\n",
      "Extraction patche: 181000 / 200000\n",
      "Extraction patche: 182000 / 200000\n",
      "Extraction patche: 183000 / 200000\n",
      "Extraction patche: 184000 / 200000\n",
      "Extraction patche: 185000 / 200000\n",
      "Extraction patche: 186000 / 200000\n",
      "Extraction patche: 187000 / 200000\n",
      "Extraction patche: 188000 / 200000\n",
      "Extraction patche: 189000 / 200000\n",
      "Extraction patche: 190000 / 200000\n",
      "Extraction patche: 191000 / 200000\n",
      "Extraction patche: 192000 / 200000\n",
      "Extraction patche: 193000 / 200000\n",
      "Extraction patche: 194000 / 200000\n",
      "Extraction patche: 195000 / 200000\n",
      "Extraction patche: 196000 / 200000\n",
      "Extraction patche: 197000 / 200000\n",
      "Extraction patche: 198000 / 200000\n",
      "Extraction patche: 199000 / 200000\n",
      "[ 1.63764887  1.82457212  1.8954724   2.4464961   1.42524046  0.62875391\n",
      "  1.5050325   0.97667896  1.99986393  1.75696394  0.71187468  0.96753452\n",
      "  0.53730794  0.54400619  0.51499247  1.63167673  0.77017729  0.38151502\n",
      "  0.31257546  0.39383857  0.2584862   1.3234756   1.02408357  0.04494415\n",
      "  0.53974628  0.41753826  0.38434101  0.45055189  0.53565482 -0.00850846\n",
      "  0.56261994  0.4923333   0.2019408  -0.06292573  0.17877157  0.58011417\n",
      "  0.64256265  0.88536377  1.16647319  1.90332312  0.66074847 -0.38253073\n",
      "  0.77429072  0.22323616  1.40271992  1.34479763 -0.04887164 -0.06556966\n",
      " -0.36881041 -0.35967224 -0.25820976  1.09480442  0.01303905 -0.62294111\n",
      " -0.6957294  -0.63632297 -0.66517974  0.55913009  0.19208751 -0.90636855\n",
      " -0.44228609 -0.53548406 -0.51312726 -0.41626943 -0.34859376 -0.93493604\n",
      " -0.31735305 -0.40998184 -0.72202071 -1.03282654 -0.80880972 -0.39917539\n",
      " -0.34438146  0.03075771  0.52000674  1.44112709 -0.05090665 -1.34401741\n",
      " -0.05918948 -0.58153375  0.75437331  0.93229233 -0.66028789 -0.90218084\n",
      " -1.17735945 -1.19110332 -0.95826901  0.55328874 -0.62570746 -1.3582797\n",
      " -1.60584765 -1.49272181 -1.44201359 -0.11081476 -0.49811165 -1.56431734\n",
      " -1.42640317 -1.51707072 -1.41533463 -1.21271569 -1.0369609  -1.54048268\n",
      " -1.37738102 -1.39012464 -1.6478268  -1.82822182 -1.54830411 -1.08087252]\n"
     ]
    }
   ],
   "source": [
    "#create unsurpervised data\n",
    "import numpy as np\n",
    "patches=[]\n",
    "rfSize = 6\n",
    "numCentroids=100\n",
    "whitening=True\n",
    "numPatches = 200000\n",
    "\n",
    "CIFAR_DIM=[32,32,3]\n",
    "numPatches = 200000\n",
    "rfSize = 6\n",
    "patches= np.zeros((numPatches, rfSize*rfSize*3))\n",
    "for i in range(0, numPatches):\n",
    "    if i%1000==0:\n",
    "        print('Extraction patche:', i, '/', numPatches)\n",
    "    # selection d'un entier alÃ©atoire entre 0 et 26 (pour pas dÃ©passer le format image 32 par 32)\n",
    "    r= np.random.randint(CIFAR_DIM[0]-rfSize) \n",
    "    c= np.random.randint(CIFAR_DIM[0]-rfSize)\n",
    "    # on utilise ici le modulo pour extraire plusieurs patchs par image\n",
    "    #(tous les len(X_train) un patche sera issu d'une mÃªme image \n",
    "    patch= (X_train[(i%len(X_train)),:])  \n",
    "    \n",
    "   #1Ã¨re dimension 3 , 2eme 32 , 3eme 32, ici taille du patch Ã  taille voulut [3,6,6]\n",
    "\n",
    "    patch= patch[:,r:r+rfSize, c:c+rfSize]\n",
    "  #on reshape le patch pour qu'il soit un vecteut (1, rfsize*rfisize*3) et le fait rent\n",
    "    # dans le tableau de patches Ã  la iÃ¨me ligne\n",
    "    patches[i]=(patch.reshape(1,-1))\n",
    "#Normalise les patches \n",
    "patches=(patches-patches.mean(1)[:,None])/np.sqrt(patches.var(1)+10)[:,None]\n",
    "\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "#patches = preprocessing.normalize(patches, norm='l2')\n",
    "\n",
    "#Normlize\n",
    "print(patches[0])\n",
    "if whitening ==True: \n",
    "    [D,V]=np.linalg.eig(np.cov(patches,rowvar=0))\n",
    "\n",
    "    P = V.dot(np.diag(np.sqrt(1/(D + 0.1)))).dot(V.T)\n",
    "    patches = patches.dot(P)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "(25, 108)\n"
     ]
    }
   ],
   "source": [
    "## We can also use the run_kmeans I have code below \n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=25, n_init=5, max_iter=100, init_size=300, batch_size=1000).fit(patches)\n",
    "Nrep= kmeans.cluster_centers_\n",
    "NrepL= list(Nrep)\n",
    "print(len(Nrep))\n",
    "array= np.array(Nrep)\n",
    "centroids=array\n",
    "print(array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def run_kmeans(X,k,iterations):\n",
    "    x2= np.sum(np.power(X,2), axis=1)\n",
    "   #centroids = valeur alÃ©toire suivant la loi normale \n",
    "    centroids= np.random.randn(k, np.size(X,1))*0.1\n",
    "    \n",
    "    BATCH_SIZE=1000\n",
    "    \n",
    "    for itr in range(1,iterations+1):\n",
    "        print('kmeans iteration ', itr ,'/', iterations)\n",
    "        c2= 0.5*np.sum(np.power(centroids,2), axis=1)\n",
    "        summation= np.zeros((k, np.size(X,1))) \n",
    "       \n",
    "        count1=[]\n",
    "        loss=0\n",
    "        c=0\n",
    "        for i in range(1,len(X), BATCH_SIZE ):\n",
    "            lastindex=min(i+BATCH_SIZE-1, len(X))\n",
    "            \n",
    "            m= lastindex -i +1 \n",
    "            \n",
    "            batch= X[i-1:lastindex ,:]  \n",
    "            batch_t=batch.transpose()\n",
    "            tmp= centroids.dot(batch_t)\n",
    "            for n in range(1, len(batch)):\n",
    "                tmp[:,n]=tmp[:,n]-c2\n",
    "                \n",
    "            val=[]\n",
    "            labels=[]\n",
    "            [val ,labels] = [np.max(tmp, axis=0),np.argmax(tmp, axis=0) ]   \n",
    "            \n",
    "            loss= loss + np.sum(0.5*x2[i-1:lastindex]-val.transpose())\n",
    "        #transformer label en matrice indicatrice \n",
    "            S=np.zeros((m,k))\n",
    "          \n",
    "            for j in range(1, lastindex-i):\n",
    "                S[j][labels[j]]=1\n",
    "           \n",
    "            \n",
    "            summation = summation+(S.transpose()).dot(X[i-1:lastindex,:])\n",
    "            counts= (np.sum(S,axis=0).transpose())\n",
    "            count1.append(counts)\n",
    "          \n",
    "            c=c+1\n",
    "           \n",
    "        counts=np.sum(np.array(count1),axis=0)\n",
    "        \n",
    "        for i in range(1, k):\n",
    "            \n",
    "            if counts[i].all!=0:\n",
    "                centroids[i]=summation[i,:]/counts[i]\n",
    "            elif counts[i]==0:\n",
    "                centroids[i]=centroids[i]*0\n",
    "                   \n",
    "         #on zappe les centroids vide , pour ne pas avoir NaN value   \n",
    "        badIndex= [i for i,val in enumerate(counts) if val.any()==0]\n",
    "        centroids[badIndex,:]=0     \n",
    "            \n",
    "    return centroids, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans iteration  1 / 50\n",
      "kmeans iteration  2 / 50\n",
      "kmeans iteration  3 / 50\n",
      "kmeans iteration  4 / 50\n",
      "kmeans iteration  5 / 50\n",
      "kmeans iteration  6 / 50\n",
      "kmeans iteration  7 / 50\n",
      "kmeans iteration  8 / 50\n",
      "kmeans iteration  9 / 50\n",
      "kmeans iteration  10 / 50\n",
      "kmeans iteration  11 / 50\n",
      "kmeans iteration  12 / 50\n",
      "kmeans iteration  13 / 50\n",
      "kmeans iteration  14 / 50\n",
      "kmeans iteration  15 / 50\n",
      "kmeans iteration  16 / 50\n",
      "kmeans iteration  17 / 50\n",
      "kmeans iteration  18 / 50\n",
      "kmeans iteration  19 / 50\n",
      "kmeans iteration  20 / 50\n",
      "kmeans iteration  21 / 50\n",
      "kmeans iteration  22 / 50\n",
      "kmeans iteration  23 / 50\n",
      "kmeans iteration  24 / 50\n",
      "kmeans iteration  25 / 50\n",
      "kmeans iteration  26 / 50\n",
      "kmeans iteration  27 / 50\n",
      "kmeans iteration  28 / 50\n",
      "kmeans iteration  29 / 50\n",
      "kmeans iteration  30 / 50\n",
      "kmeans iteration  31 / 50\n",
      "kmeans iteration  32 / 50\n",
      "kmeans iteration  33 / 50\n",
      "kmeans iteration  34 / 50\n",
      "kmeans iteration  35 / 50\n",
      "kmeans iteration  36 / 50\n",
      "kmeans iteration  37 / 50\n",
      "kmeans iteration  38 / 50\n",
      "kmeans iteration  39 / 50\n",
      "kmeans iteration  40 / 50\n",
      "kmeans iteration  41 / 50\n",
      "kmeans iteration  42 / 50\n",
      "kmeans iteration  43 / 50\n",
      "kmeans iteration  44 / 50\n",
      "kmeans iteration  45 / 50\n",
      "kmeans iteration  46 / 50\n",
      "kmeans iteration  47 / 50\n",
      "kmeans iteration  48 / 50\n",
      "kmeans iteration  49 / 50\n",
      "kmeans iteration  50 / 50\n"
     ]
    }
   ],
   "source": [
    "centroids=run_kmeans(patches,numCentroids,50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids= np.array(centroids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction patche: 0 / 200000\n",
      "Extraction patche: 1000 / 200000\n",
      "Extraction patche: 2000 / 200000\n",
      "Extraction patche: 3000 / 200000\n",
      "Extraction patche: 4000 / 200000\n",
      "Extraction patche: 5000 / 200000\n",
      "Extraction patche: 6000 / 200000\n",
      "Extraction patche: 7000 / 200000\n",
      "Extraction patche: 8000 / 200000\n",
      "Extraction patche: 9000 / 200000\n",
      "Extraction patche: 10000 / 200000\n",
      "Extraction patche: 11000 / 200000\n",
      "Extraction patche: 12000 / 200000\n",
      "Extraction patche: 13000 / 200000\n",
      "Extraction patche: 14000 / 200000\n",
      "Extraction patche: 15000 / 200000\n",
      "Extraction patche: 16000 / 200000\n",
      "Extraction patche: 17000 / 200000\n",
      "Extraction patche: 18000 / 200000\n",
      "Extraction patche: 19000 / 200000\n",
      "Extraction patche: 20000 / 200000\n",
      "Extraction patche: 21000 / 200000\n",
      "Extraction patche: 22000 / 200000\n",
      "Extraction patche: 23000 / 200000\n",
      "Extraction patche: 24000 / 200000\n",
      "Extraction patche: 25000 / 200000\n",
      "Extraction patche: 26000 / 200000\n",
      "Extraction patche: 27000 / 200000\n",
      "Extraction patche: 28000 / 200000\n",
      "Extraction patche: 29000 / 200000\n",
      "Extraction patche: 30000 / 200000\n",
      "Extraction patche: 31000 / 200000\n",
      "Extraction patche: 32000 / 200000\n",
      "Extraction patche: 33000 / 200000\n",
      "Extraction patche: 34000 / 200000\n",
      "Extraction patche: 35000 / 200000\n",
      "Extraction patche: 36000 / 200000\n",
      "Extraction patche: 37000 / 200000\n",
      "Extraction patche: 38000 / 200000\n",
      "Extraction patche: 39000 / 200000\n",
      "Extraction patche: 40000 / 200000\n",
      "Extraction patche: 41000 / 200000\n",
      "Extraction patche: 42000 / 200000\n",
      "Extraction patche: 43000 / 200000\n",
      "Extraction patche: 44000 / 200000\n",
      "Extraction patche: 45000 / 200000\n",
      "Extraction patche: 46000 / 200000\n",
      "Extraction patche: 47000 / 200000\n",
      "Extraction patche: 48000 / 200000\n",
      "Extraction patche: 49000 / 200000\n",
      "Extraction patche: 50000 / 200000\n",
      "Extraction patche: 51000 / 200000\n",
      "Extraction patche: 52000 / 200000\n",
      "Extraction patche: 53000 / 200000\n",
      "Extraction patche: 54000 / 200000\n",
      "Extraction patche: 55000 / 200000\n",
      "Extraction patche: 56000 / 200000\n",
      "Extraction patche: 57000 / 200000\n",
      "Extraction patche: 58000 / 200000\n",
      "Extraction patche: 59000 / 200000\n",
      "Extraction patche: 60000 / 200000\n",
      "Extraction patche: 61000 / 200000\n",
      "Extraction patche: 62000 / 200000\n",
      "Extraction patche: 63000 / 200000\n",
      "Extraction patche: 64000 / 200000\n",
      "Extraction patche: 65000 / 200000\n",
      "Extraction patche: 66000 / 200000\n",
      "Extraction patche: 67000 / 200000\n",
      "Extraction patche: 68000 / 200000\n",
      "Extraction patche: 69000 / 200000\n",
      "Extraction patche: 70000 / 200000\n",
      "Extraction patche: 71000 / 200000\n",
      "Extraction patche: 72000 / 200000\n",
      "Extraction patche: 73000 / 200000\n",
      "Extraction patche: 74000 / 200000\n",
      "Extraction patche: 75000 / 200000\n",
      "Extraction patche: 76000 / 200000\n",
      "Extraction patche: 77000 / 200000\n",
      "Extraction patche: 78000 / 200000\n",
      "Extraction patche: 79000 / 200000\n",
      "Extraction patche: 80000 / 200000\n",
      "Extraction patche: 81000 / 200000\n",
      "Extraction patche: 82000 / 200000\n",
      "Extraction patche: 83000 / 200000\n",
      "Extraction patche: 84000 / 200000\n",
      "Extraction patche: 85000 / 200000\n",
      "Extraction patche: 86000 / 200000\n",
      "Extraction patche: 87000 / 200000\n",
      "Extraction patche: 88000 / 200000\n",
      "Extraction patche: 89000 / 200000\n",
      "Extraction patche: 90000 / 200000\n",
      "Extraction patche: 91000 / 200000\n",
      "Extraction patche: 92000 / 200000\n",
      "Extraction patche: 93000 / 200000\n",
      "Extraction patche: 94000 / 200000\n",
      "Extraction patche: 95000 / 200000\n",
      "Extraction patche: 96000 / 200000\n",
      "Extraction patche: 97000 / 200000\n",
      "Extraction patche: 98000 / 200000\n",
      "Extraction patche: 99000 / 200000\n",
      "Extraction patche: 100000 / 200000\n",
      "Extraction patche: 101000 / 200000\n",
      "Extraction patche: 102000 / 200000\n",
      "Extraction patche: 103000 / 200000\n",
      "Extraction patche: 104000 / 200000\n",
      "Extraction patche: 105000 / 200000\n",
      "Extraction patche: 106000 / 200000\n",
      "Extraction patche: 107000 / 200000\n",
      "Extraction patche: 108000 / 200000\n",
      "Extraction patche: 109000 / 200000\n",
      "Extraction patche: 110000 / 200000\n",
      "Extraction patche: 111000 / 200000\n",
      "Extraction patche: 112000 / 200000\n",
      "Extraction patche: 113000 / 200000\n",
      "Extraction patche: 114000 / 200000\n",
      "Extraction patche: 115000 / 200000\n",
      "Extraction patche: 116000 / 200000\n",
      "Extraction patche: 117000 / 200000\n",
      "Extraction patche: 118000 / 200000\n",
      "Extraction patche: 119000 / 200000\n",
      "Extraction patche: 120000 / 200000\n",
      "Extraction patche: 121000 / 200000\n",
      "Extraction patche: 122000 / 200000\n",
      "Extraction patche: 123000 / 200000\n",
      "Extraction patche: 124000 / 200000\n",
      "Extraction patche: 125000 / 200000\n",
      "Extraction patche: 126000 / 200000\n",
      "Extraction patche: 127000 / 200000\n",
      "Extraction patche: 128000 / 200000\n",
      "Extraction patche: 129000 / 200000\n",
      "Extraction patche: 130000 / 200000\n",
      "Extraction patche: 131000 / 200000\n",
      "Extraction patche: 132000 / 200000\n",
      "Extraction patche: 133000 / 200000\n",
      "Extraction patche: 134000 / 200000\n",
      "Extraction patche: 135000 / 200000\n",
      "Extraction patche: 136000 / 200000\n",
      "Extraction patche: 137000 / 200000\n",
      "Extraction patche: 138000 / 200000\n",
      "Extraction patche: 139000 / 200000\n",
      "Extraction patche: 140000 / 200000\n",
      "Extraction patche: 141000 / 200000\n",
      "Extraction patche: 142000 / 200000\n",
      "Extraction patche: 143000 / 200000\n",
      "Extraction patche: 144000 / 200000\n",
      "Extraction patche: 145000 / 200000\n",
      "Extraction patche: 146000 / 200000\n",
      "Extraction patche: 147000 / 200000\n",
      "Extraction patche: 148000 / 200000\n",
      "Extraction patche: 149000 / 200000\n",
      "Extraction patche: 150000 / 200000\n",
      "Extraction patche: 151000 / 200000\n",
      "Extraction patche: 152000 / 200000\n",
      "Extraction patche: 153000 / 200000\n",
      "Extraction patche: 154000 / 200000\n",
      "Extraction patche: 155000 / 200000\n",
      "Extraction patche: 156000 / 200000\n",
      "Extraction patche: 157000 / 200000\n",
      "Extraction patche: 158000 / 200000\n",
      "Extraction patche: 159000 / 200000\n",
      "Extraction patche: 160000 / 200000\n",
      "Extraction patche: 161000 / 200000\n",
      "Extraction patche: 162000 / 200000\n",
      "Extraction patche: 163000 / 200000\n",
      "Extraction patche: 164000 / 200000\n",
      "Extraction patche: 165000 / 200000\n",
      "Extraction patche: 166000 / 200000\n",
      "Extraction patche: 167000 / 200000\n",
      "Extraction patche: 168000 / 200000\n",
      "Extraction patche: 169000 / 200000\n",
      "Extraction patche: 170000 / 200000\n",
      "Extraction patche: 171000 / 200000\n",
      "Extraction patche: 172000 / 200000\n",
      "Extraction patche: 173000 / 200000\n",
      "Extraction patche: 174000 / 200000\n",
      "Extraction patche: 175000 / 200000\n",
      "Extraction patche: 176000 / 200000\n",
      "Extraction patche: 177000 / 200000\n",
      "Extraction patche: 178000 / 200000\n",
      "Extraction patche: 179000 / 200000\n",
      "Extraction patche: 180000 / 200000\n",
      "Extraction patche: 181000 / 200000\n",
      "Extraction patche: 182000 / 200000\n",
      "Extraction patche: 183000 / 200000\n",
      "Extraction patche: 184000 / 200000\n",
      "Extraction patche: 185000 / 200000\n",
      "Extraction patche: 186000 / 200000\n",
      "Extraction patche: 187000 / 200000\n",
      "Extraction patche: 188000 / 200000\n",
      "Extraction patche: 189000 / 200000\n",
      "Extraction patche: 190000 / 200000\n",
      "Extraction patche: 191000 / 200000\n",
      "Extraction patche: 192000 / 200000\n",
      "Extraction patche: 193000 / 200000\n",
      "Extraction patche: 194000 / 200000\n",
      "Extraction patche: 195000 / 200000\n",
      "Extraction patche: 196000 / 200000\n",
      "Extraction patche: 197000 / 200000\n",
      "Extraction patche: 198000 / 200000\n",
      "Extraction patche: 199000 / 200000\n"
     ]
    }
   ],
   "source": [
    "# Generation d'autre patches alÃ©atoire \n",
    "patches1= np.zeros((numPatches, rfSize*rfSize*3))\n",
    "for i in range(0, numPatches):\n",
    "    if i%1000==0:\n",
    "        print('Extraction patche:', i, '/', numPatches)\n",
    "    r= np.random.randint(CIFAR_DIM[0]-rfSize) \n",
    "    c= np.random.randint(CIFAR_DIM[0]-rfSize)\n",
    "    patch= (X_train[(i%len(X_train)),:])  \n",
    "\n",
    "    patch= patch[:,r:r+rfSize, c:c+rfSize]\n",
    "  \n",
    "    patches1[i]=(patch.reshape(1,-1))\n",
    "patches1=(patches1-patches1.mean(1)[:,None])/np.sqrt(patches1.var(1)+10)[:,None]\n",
    "\n",
    "#matrice withening\n",
    "patches1=patches1.dot(P)\n",
    "\n",
    "#Calcul des distances patches Centroids \n",
    "x2=np.power(patches1,2).sum(1)\n",
    "c2=np.power(centroids,2).sum(1)\n",
    "xc=patches1.dot(centroids.T)\n",
    "dist=np.sqrt(-2*xc+x2[:,None]+c2)\n",
    "\n",
    "#Recuperation des Index Minimum\n",
    "indexMin=[]\n",
    "for i in range(0, len(dist)):\n",
    "    indexMin.append(np.argmin(dist[i]))\n",
    "    \n",
    "NewRep= np.zeros((len(X_train),4))\n",
    "j=0\n",
    "\n",
    "for i in range(0, len(dist)-4000):\n",
    "    \n",
    "    NewRep[i%len(X_train),j]=indexMin[i]\n",
    "    \n",
    "    if i== (j+1)*len(X_train):\n",
    "        j=j+1\n",
    "#Nouvelle reprÃ©sentation vectorielle \n",
    "NewRepBis=np.zeros((len(X_train),4*numCentroids))\n",
    "for i in range(0, len(NewRep)):\n",
    "    NewRepBis[i, int(NewRep[i,0])]=1\n",
    "    NewRepBis[i, numCentroids+int(NewRep[i,1])]=1\n",
    "    NewRepBis[i, 2*numCentroids+int(NewRep[i,2])]=1\n",
    "    NewRepBis[i, 3*numCentroids+int(NewRep[i,3])]=1    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewRepBis=np.zeros((len(X_train),4*numCentroids))\n",
    "for i in range(0, len(NewRep)):\n",
    "    NewRepBis[i, int(NewRep[i,0])]=1\n",
    "    NewRepBis[i, numCentroids+int(NewRep[i,1])]=1\n",
    "    NewRepBis[i, 2*numCentroids+int(NewRep[i,2])]=1\n",
    "    NewRepBis[i, 3*numCentroids+int(NewRep[i,3])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=NewRepBis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(A, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22583673469387755"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(A,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function Im2col allows to find overllaping patch\n",
    "\n",
    "def im2col_sliding_broadcasting(A, BSZ, stepsize=1):\n",
    "    # Parameters\n",
    "    M,N = A.shape\n",
    "    col_extent = N - BSZ[1] + 1\n",
    "    row_extent = M - BSZ[0] + 1\n",
    "\n",
    "    # Get Starting block indices\n",
    "    start_idx = np.arange(BSZ[0])[:,None]*N + np.arange(BSZ[1])\n",
    "\n",
    "    # Get offsetted indices across the height and width of input array\n",
    "    offset_idx = np.arange(row_extent)[:,None]*N + np.arange(col_extent)\n",
    "\n",
    "    # Get all actual indices & index into input array for final output\n",
    "    return np.take (A,start_idx.ravel()[:,None] + offset_idx.ravel()[::stepsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import distance\n",
    "#XC = np.zeros((50000,4*100))\n",
    "def extract_features (X):\n",
    "    #(nargin==6)\n",
    "    trainXC=[]\n",
    "    liste=[]\n",
    "    for i in range(0, len(X)):\n",
    "        if (i%1000==0):\n",
    "            print('Extraction features: ')#+i+ '/'+ len(X))\n",
    "            \n",
    "        #shape de patches (729,108)    \n",
    "        patches =np.concatenate([im2col_sliding_broadcasting((X[i].reshape(-1,1)[0:1024]).reshape(32,32) , [6,6], stepsize=1)\n",
    "        ,im2col_sliding_broadcasting((X[i].reshape(-1,1)[1024:2048]).reshape(32,32), [6,6], stepsize=1),\n",
    "        im2col_sliding_broadcasting((X[i].reshape(-1,1)[2048:]).reshape(32,32),[ 6,6], stepsize=1) ], axis=0)\n",
    "        patches=patches.transpose()\n",
    "        \n",
    "        patches=np.array(patches)\n",
    "        \n",
    "        \n",
    "        patches=(patches-patches.mean(1)[:,None])/(np.sqrt(patches.var(1)+10)[:,None])\n",
    "        #map to feature space\n",
    "        if whitening==True:\n",
    "            patches=patches.dot(P)\n",
    "            \n",
    "            \n",
    "        #calculate distance using x2-2xc+c2\n",
    "        x2=np.power(patches,2).sum(1)\n",
    "        c2=np.power(centroids,2).sum(1)\n",
    "        xc=patches.dot(centroids.T)\n",
    "        dist=np.sqrt(-2*xc+x2[:,None]+c2)\n",
    "        \n",
    "       #patches.dot(P) si matrice\n",
    "      \n",
    "        \n",
    "        \n",
    "        z =dist # 13h          \n",
    "      \n",
    "        \n",
    "        u=dist.mean(1)\n",
    "        patches=np.maximum(-dist+u[:,None],0)\n",
    "        rs=CIFAR_DIM[0]-rfSize+1\n",
    "        cs=CIFAR_DIM[1]-rfSize+1\n",
    "        patches=np.reshape(patches,[rs,cs,-1])\n",
    "        q=[]\n",
    "        q.append(patches[0:int(rs/2)+1,0:int(cs/2)+1].sum(0).sum(0))\n",
    "        q.append(patches[0:int(rs/2)+1,int(cs/2)+1:cs-1].sum(0).sum(0))\n",
    "        q.append(patches[int(rs/2)+1:rs-1,0:int(cs/2)+1].sum(0).sum(0))\n",
    "        q.append(patches[int(rs/2)+1:rs-1,int(cs/2)+1:cs-1].sum(0).sum(0))\n",
    "        q=np.array(q).ravel()\n",
    "        trainXC.append(q)\n",
    "    trainXC=np.array(trainXC)\n",
    "    trainXC=(trainXC-trainXC.mean(1)[:,None])/(np.sqrt(trainXC.var(1)+.01)[:,None])\n",
    "    return trainXC\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "### Calcul of features , with matrices distances ,take distance < mean(distance) + pooling patches\n",
    "\n",
    "#Extract features of Xtrain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A=extract_features (X_train )\n",
    "\n",
    "print(np.shape(A[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 100)\n",
      "Extraction features: \n"
     ]
    }
   ],
   "source": [
    "#Extract features of X_test \n",
    "print(A.shape)\n",
    "\n",
    "BBB=extract_features (X_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train svm classifier \n",
    "\n",
    "import numpy as np\n",
    "def my_l2svmloss(w, *args):\n",
    "    #print(len(args))\n",
    "    X=args[0]\n",
    "    y=args[1]\n",
    "    K=args[2]\n",
    "    C=args[3]\n",
    "    [M,N]= np.shape(X)   \n",
    "    theta= w.reshape(N,K)  \n",
    "    Y= np.zeros((len(y),K))   \n",
    "    for i in range(0, len(y)):\n",
    "        for k in range(1, K+1):\n",
    "            if y[i]==k:\n",
    "                Y[i,k-1]=Y[i,k-1]+1       \n",
    "            else: Y[i,k-1]=Y[i,k-1]-1\n",
    "\n",
    "    margin = np.maximum(0, 1-Y*(X.dot(theta)))    \n",
    "  \n",
    "    loss= (0.5* np.sum((np.power(theta,2)), axis=0))+ C*np.mean((np.power(margin,2)), axis=0)\n",
    "  \n",
    "    loss= np.sum(loss, axis=0) \n",
    "  \n",
    "    g = theta -2*C/M*(X.transpose().dot(margin*Y))\n",
    "    g.reshape(np.size(X, 1)*K,1)\n",
    "  \n",
    "    return loss, np.hstack(g)\n",
    "\n",
    "#objectif mininimiser loss et g \n",
    "\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "def train_svm(trainXC, trainY, C):\n",
    "    X= trainXC   #featurize data \n",
    "    y= trainY   \n",
    "    \n",
    "    K = np.max(trainY)  #number of classes \n",
    "    \n",
    "    w0= np.zeros((np.size(X, 1)*K,1) )# 10* (4*numcentroids+1) , w vector of weight for the 10 classes \n",
    "    w0=np.array(w0)\n",
    "    #minimize the function svmloss\n",
    "    w, fw ,i   = fmin_l_bfgs_b(my_l2svmloss,w0,args =([X,y,K,C  ]), maxfun=1000, maxiter=1000)  #x,f,d   / w, fw, i\n",
    "   \n",
    "    theta= w.reshape(np.size(trainXC, 1), K )\n",
    "    return theta \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "import numpy as np\n",
    "#Asc = preprocessing.scale(A)\n",
    "\n",
    "#Standardize the data \n",
    "#Asc= A- np.mean(A,axis=0)\n",
    "#Asc= Asc/np.sqrt(np.var(A,axis=0)+0.01)\n",
    "#One= np.array([1]*49000)\n",
    "\n",
    "Asc=np.c_[ A, np.ones(len(A)) ] \n",
    "\n",
    "#train SVM with with the features of A (features from Xtrain) standardised , and Y_train=Cifar[1]+1\n",
    "\n",
    "theta=train_svm(Asc, y_train+1 , 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train result :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26816326530612244"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we find with f_min the function who find w  who minimize the fonction svmloss\n",
    "\n",
    "Matrice = Asc.dot(theta)      #theta= w  theta shape : (4* num Centroids, number of class ), Asc= x ,\n",
    "#Asc.shape = 50000, 4*numCentroids, Matrice (50000, 10) argamx axis= 1 sort the number of the class predict \n",
    "#higher score with weight vector \n",
    "[val1 ,inds1] = [np.max(Matrice, axis=1),np.argmax(Matrice, axis=1) ]  #y_pred= argmax(x*wy)\n",
    "print('train result :')\n",
    "(inds1==y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data of X_test with the data X_train\n",
    "reserve=BBB\n",
    "BBB=BBB- np.mean(A,axis=0)\n",
    "BBB= BBB/ np.sqrt(np.var(A,axis=0)+0.01)\n",
    "Bsc=np.c_[ BBB, np.ones(len(BBB)) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuraccy result on Xtest:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.468"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MatriceTest= Bsc.dot(theta)\n",
    "[val2 ,inds2] = [np.max(MatriceTest, axis=1),np.argmax(MatriceTest, axis=1) ]\n",
    "print('Accuraccy result on Xtest:')\n",
    "(inds2==y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction features: \n",
      "Accuraccy result on Xtest:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.449"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=extract_features (X_test )\n",
    "test=test- np.mean(A,axis=0)\n",
    "test= test/ np.sqrt(np.var(A,axis=0)+0.01)\n",
    "Tsc=np.c_[test, np.ones(len(test)) ] \n",
    "MatriceTest1= Tsc.dot(theta)\n",
    "[val3 ,inds3] = [np.max(MatriceTest1, axis=1),np.argmax(MatriceTest1, axis=1) ]\n",
    "print('Accuraccy result on Xtest:')\n",
    "(inds3==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Confusion matrix, without normalization\n",
      "[[42  9  1  2  2  4  5  8 24  6]\n",
      " [ 4 55  2  1  2  1  5  0 10  9]\n",
      " [17  2 13 12  8 12 15 13  2  6]\n",
      " [ 2  6  4 30  4 21 13 10  3 10]\n",
      " [ 8  5  7  7 23  5 11 17  4  3]\n",
      " [ 0  4  5 18  5 35 10  8  0  1]\n",
      " [ 1  4  5  4  5  6 72 10  1  4]\n",
      " [ 2  4  1  5  3 14  4 64  2  3]\n",
      " [23 11  0  2  1  1  1  1 61  5]\n",
      " [ 5 18  0  2  1  3 11  5 10 54]]\n",
      "Normalized confusion matrix\n",
      "[[0.41 0.09 0.01 0.02 0.02 0.04 0.05 0.08 0.23 0.06]\n",
      " [0.04 0.62 0.02 0.01 0.02 0.01 0.06 0.   0.11 0.1 ]\n",
      " [0.17 0.02 0.13 0.12 0.08 0.12 0.15 0.13 0.02 0.06]\n",
      " [0.02 0.06 0.04 0.29 0.04 0.2  0.13 0.1  0.03 0.1 ]\n",
      " [0.09 0.06 0.08 0.08 0.26 0.06 0.12 0.19 0.04 0.03]\n",
      " [0.   0.05 0.06 0.21 0.06 0.41 0.12 0.09 0.   0.01]\n",
      " [0.01 0.04 0.04 0.04 0.04 0.05 0.64 0.09 0.01 0.04]\n",
      " [0.02 0.04 0.01 0.05 0.03 0.14 0.04 0.63 0.02 0.03]\n",
      " [0.22 0.1  0.   0.02 0.01 0.01 0.01 0.01 0.58 0.05]\n",
      " [0.05 0.17 0.   0.02 0.01 0.03 0.1  0.05 0.09 0.5 ]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "%matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test = y_test\n",
    "y_pred = inds3\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['airplane', 'automobile', 'bird', 'cat', 'deer' ,'dog', 'frog', 'horse' ,'ship' ,'truck'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['airplane', 'automobile', 'bird', 'cat', 'deer' ,'dog', 'frog', 'horse' ,'ship' ,'truck'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = A.shape[1]\n",
    "hidden_size = 200\n",
    "num_classes = 10\n",
    "\n",
    "Asc1= A- np.mean(A,axis=0)\n",
    "Asc1= Asc1/np.sqrt(np.var(A,axis=0)+0.01)\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes,1e-4)\n",
    "stats = net.train(Asc1, Cifar[1] , BBB, Cifar[3] ,\n",
    "                            num_iters=70000, batch_size=128,\n",
    "                            learning_rate=5e-4, learning_rate_decay=0.99,\n",
    "                            reg=0, verbose=True,update=\"SGD\",arg=0.95,dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = (net.predict(Asc1) == Cifar[1]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29787999999999998"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout , Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import sklearn.preprocessing\n",
    "from keras.optimizers import SGD\n",
    "#optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon = 1e-06, decay=1e-6)\n",
    "\n",
    "a=y_train\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(max(a)+1))\n",
    "C1=label_binarizer.transform(a)\n",
    "b=y_val\n",
    "C2=label_binarizer.transform(b)\n",
    "model= Sequential()\n",
    "model.add(Dense(50,input_shape=(A.shape[1],)))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon = 1e-06, decay=1e-6), metrics=['accuracy'])\n",
    "history = model.fit(A, C1 , batch_size=1000, epochs=1000, verbose=2, validation_split=0.2)\n",
    "loss_and_metrics= model.evaluate(BBB, C2)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import distance\n",
    "#XC = np.zeros((50000,4*100))\n",
    "def extract_features (X):\n",
    "    whitening = True #(nargin==6)\n",
    "    trainXC=[]\n",
    "    liste=[]\n",
    "    for i in range(0, len(X)):\n",
    "        if (i%1000==0):\n",
    "            print('Extraction features: ')#+i+ '/'+ len(X))\n",
    "            \n",
    "        #shape de patches (729,108)    \n",
    "        patches =np.concatenate([im2col_sliding_broadcasting((X[i].reshape(-1,1)[0:1024]).reshape(32,32) , [6,6], stepsize=1)\n",
    "        ,im2col_sliding_broadcasting((X[i].reshape(-1,1)[1024:2048]).reshape(32,32), [6,6], stepsize=1),\n",
    "        im2col_sliding_broadcasting((X[i].reshape(-1,1)[2048:]).reshape(32,32),[ 6,6], stepsize=1) ], axis=0)\n",
    "        patches=patches.transpose()\n",
    "        \n",
    "        patches=np.array(patches)\n",
    "        \n",
    "        NumCentroids= np.size(Centroids,0)\n",
    "        \n",
    "        patches=(patches-patches.mean(1)[:,None])/(np.sqrt(patches.var(1)+10)[:,None])\n",
    "        #map to feature space\n",
    "        patches=patches.dot(P)\n",
    "        #calculate distance using x2-2xc+c2\n",
    "        x2=np.power(patches,2).sum(1)\n",
    "        c2=np.power(centroids,2).sum(1)\n",
    "        xc=patches.dot(centroids.T)\n",
    "        dist=np.sqrt(-2*xc+x2[:,None]+c2)\n",
    "        \n",
    "       #patches.dot(P) si matrice\n",
    "      \n",
    "        \n",
    "        \n",
    "        z =dist # 13h          \n",
    "      \n",
    "        \n",
    "        u=dist.mean(1)\n",
    "        patches=np.maximum(-dist+u[:,None],0)\n",
    "        rs=CIFAR_DIM[0]-rfSize+1\n",
    "        cs=CIFAR_DIM[1]-rfSize+1\n",
    "        patches=np.reshape(patches,[rs,cs,-1])\n",
    "        q=[]\n",
    "        q.append(patches[0:int(rs/2)+1,0:int(cs/2)+1].sum(0).sum(0))\n",
    "        q.append(patches[0:int(rs/2)+1,int(cs/2)+1:cs-1].sum(0).sum(0))\n",
    "        q.append(patches[int(rs/2)+1:rs-1,0:int(cs/2)+1].sum(0).sum(0))\n",
    "        q.append(patches[int(rs/2)+1:rs-1,int(cs/2)+1:cs-1].sum(0).sum(0))\n",
    "        q=np.array(q).ravel()\n",
    "        trainXC.append(q)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    trainXC=np.array(trainXC)\n",
    "    trainXC=(trainXC-trainXC.mean(1)[:,None])/(np.sqrt(trainXC.var(1)+.01)[:,None])\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return trainXC\n",
    "\n",
    "\n",
    "for line in trainXC:\n",
    "    line= np.split(line, 4)\n",
    "    indiceMax=[]\n",
    "    j=0\n",
    "    for e in line:\n",
    "        indiceMax.append(argmax(e)+j)\n",
    "        j=j+numCentroids\n",
    "    for el not in indiceMax:\n",
    "        trainXC[line, el]=0\n",
    "    for el in indiceMax:\n",
    "        trainXC[line, el]=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

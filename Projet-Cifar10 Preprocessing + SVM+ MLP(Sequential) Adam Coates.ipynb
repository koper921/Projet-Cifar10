{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "#from scipy.misc import imread\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats.mstats import mode\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f,encoding='latin1')\n",
    "    X = datadict['data']\n",
    "    \n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"double\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)    \n",
    "  Xtr = np.concatenate(xs)\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "#Normalise la base - la moyenne , divise par std, resultat final toujours mauvais normalis√© ou non\n",
    "#Normalize the data, by soustracting the mean and dividing the standart deviation \n",
    "  mean_image = np.mean(Xtr, axis=0)\n",
    "  std_image=np.std(Xtr, axis=0)\n",
    "  #Xtr -= mean_image\n",
    "  #Xtr /= std_image\n",
    "  \n",
    "  #Xte -= mean_image\n",
    "  #Xte /= std_image\n",
    "  return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    cifar10_dir = 'C:/Users/MyPC/Desktop/Projet Apprentissage Image/cifar-10-batches-py/'\n",
    "    \n",
    "    print (len(load_CIFAR10(cifar10_dir)))\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_train=X_train.swapaxes(1,3)\n",
    "    X_val=X_val.swapaxes(1,3)\n",
    "    X_test=X_test.swapaxes(1,3)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test=get_CIFAR10_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction patche: 0 / 400000\n",
      "Extraction patche: 1000 / 400000\n",
      "Extraction patche: 2000 / 400000\n",
      "Extraction patche: 3000 / 400000\n",
      "Extraction patche: 4000 / 400000\n",
      "Extraction patche: 5000 / 400000\n",
      "Extraction patche: 6000 / 400000\n",
      "Extraction patche: 7000 / 400000\n",
      "Extraction patche: 8000 / 400000\n",
      "Extraction patche: 9000 / 400000\n",
      "Extraction patche: 10000 / 400000\n",
      "Extraction patche: 11000 / 400000\n",
      "Extraction patche: 12000 / 400000\n",
      "Extraction patche: 13000 / 400000\n",
      "Extraction patche: 14000 / 400000\n",
      "Extraction patche: 15000 / 400000\n",
      "Extraction patche: 16000 / 400000\n",
      "Extraction patche: 17000 / 400000\n",
      "Extraction patche: 18000 / 400000\n",
      "Extraction patche: 19000 / 400000\n",
      "Extraction patche: 20000 / 400000\n",
      "Extraction patche: 21000 / 400000\n",
      "Extraction patche: 22000 / 400000\n",
      "Extraction patche: 23000 / 400000\n",
      "Extraction patche: 24000 / 400000\n",
      "Extraction patche: 25000 / 400000\n",
      "Extraction patche: 26000 / 400000\n",
      "Extraction patche: 27000 / 400000\n",
      "Extraction patche: 28000 / 400000\n",
      "Extraction patche: 29000 / 400000\n",
      "Extraction patche: 30000 / 400000\n",
      "Extraction patche: 31000 / 400000\n",
      "Extraction patche: 32000 / 400000\n",
      "Extraction patche: 33000 / 400000\n",
      "Extraction patche: 34000 / 400000\n",
      "Extraction patche: 35000 / 400000\n",
      "Extraction patche: 36000 / 400000\n",
      "Extraction patche: 37000 / 400000\n",
      "Extraction patche: 38000 / 400000\n",
      "Extraction patche: 39000 / 400000\n",
      "Extraction patche: 40000 / 400000\n",
      "Extraction patche: 41000 / 400000\n",
      "Extraction patche: 42000 / 400000\n",
      "Extraction patche: 43000 / 400000\n",
      "Extraction patche: 44000 / 400000\n",
      "Extraction patche: 45000 / 400000\n",
      "Extraction patche: 46000 / 400000\n",
      "Extraction patche: 47000 / 400000\n",
      "Extraction patche: 48000 / 400000\n",
      "Extraction patche: 49000 / 400000\n",
      "Extraction patche: 50000 / 400000\n",
      "Extraction patche: 51000 / 400000\n",
      "Extraction patche: 52000 / 400000\n",
      "Extraction patche: 53000 / 400000\n",
      "Extraction patche: 54000 / 400000\n",
      "Extraction patche: 55000 / 400000\n",
      "Extraction patche: 56000 / 400000\n",
      "Extraction patche: 57000 / 400000\n",
      "Extraction patche: 58000 / 400000\n",
      "Extraction patche: 59000 / 400000\n",
      "Extraction patche: 60000 / 400000\n",
      "Extraction patche: 61000 / 400000\n",
      "Extraction patche: 62000 / 400000\n",
      "Extraction patche: 63000 / 400000\n",
      "Extraction patche: 64000 / 400000\n",
      "Extraction patche: 65000 / 400000\n",
      "Extraction patche: 66000 / 400000\n",
      "Extraction patche: 67000 / 400000\n",
      "Extraction patche: 68000 / 400000\n",
      "Extraction patche: 69000 / 400000\n",
      "Extraction patche: 70000 / 400000\n",
      "Extraction patche: 71000 / 400000\n",
      "Extraction patche: 72000 / 400000\n",
      "Extraction patche: 73000 / 400000\n",
      "Extraction patche: 74000 / 400000\n",
      "Extraction patche: 75000 / 400000\n",
      "Extraction patche: 76000 / 400000\n",
      "Extraction patche: 77000 / 400000\n",
      "Extraction patche: 78000 / 400000\n",
      "Extraction patche: 79000 / 400000\n",
      "Extraction patche: 80000 / 400000\n",
      "Extraction patche: 81000 / 400000\n",
      "Extraction patche: 82000 / 400000\n",
      "Extraction patche: 83000 / 400000\n",
      "Extraction patche: 84000 / 400000\n",
      "Extraction patche: 85000 / 400000\n",
      "Extraction patche: 86000 / 400000\n",
      "Extraction patche: 87000 / 400000\n",
      "Extraction patche: 88000 / 400000\n",
      "Extraction patche: 89000 / 400000\n",
      "Extraction patche: 90000 / 400000\n",
      "Extraction patche: 91000 / 400000\n",
      "Extraction patche: 92000 / 400000\n",
      "Extraction patche: 93000 / 400000\n",
      "Extraction patche: 94000 / 400000\n",
      "Extraction patche: 95000 / 400000\n",
      "Extraction patche: 96000 / 400000\n",
      "Extraction patche: 97000 / 400000\n",
      "Extraction patche: 98000 / 400000\n",
      "Extraction patche: 99000 / 400000\n",
      "Extraction patche: 100000 / 400000\n",
      "Extraction patche: 101000 / 400000\n",
      "Extraction patche: 102000 / 400000\n",
      "Extraction patche: 103000 / 400000\n",
      "Extraction patche: 104000 / 400000\n",
      "Extraction patche: 105000 / 400000\n",
      "Extraction patche: 106000 / 400000\n",
      "Extraction patche: 107000 / 400000\n",
      "Extraction patche: 108000 / 400000\n",
      "Extraction patche: 109000 / 400000\n",
      "Extraction patche: 110000 / 400000\n",
      "Extraction patche: 111000 / 400000\n",
      "Extraction patche: 112000 / 400000\n",
      "Extraction patche: 113000 / 400000\n",
      "Extraction patche: 114000 / 400000\n",
      "Extraction patche: 115000 / 400000\n",
      "Extraction patche: 116000 / 400000\n",
      "Extraction patche: 117000 / 400000\n",
      "Extraction patche: 118000 / 400000\n",
      "Extraction patche: 119000 / 400000\n",
      "Extraction patche: 120000 / 400000\n",
      "Extraction patche: 121000 / 400000\n",
      "Extraction patche: 122000 / 400000\n",
      "Extraction patche: 123000 / 400000\n",
      "Extraction patche: 124000 / 400000\n",
      "Extraction patche: 125000 / 400000\n",
      "Extraction patche: 126000 / 400000\n",
      "Extraction patche: 127000 / 400000\n",
      "Extraction patche: 128000 / 400000\n",
      "Extraction patche: 129000 / 400000\n",
      "Extraction patche: 130000 / 400000\n",
      "Extraction patche: 131000 / 400000\n",
      "Extraction patche: 132000 / 400000\n",
      "Extraction patche: 133000 / 400000\n",
      "Extraction patche: 134000 / 400000\n",
      "Extraction patche: 135000 / 400000\n",
      "Extraction patche: 136000 / 400000\n",
      "Extraction patche: 137000 / 400000\n",
      "Extraction patche: 138000 / 400000\n",
      "Extraction patche: 139000 / 400000\n",
      "Extraction patche: 140000 / 400000\n",
      "Extraction patche: 141000 / 400000\n",
      "Extraction patche: 142000 / 400000\n",
      "Extraction patche: 143000 / 400000\n",
      "Extraction patche: 144000 / 400000\n",
      "Extraction patche: 145000 / 400000\n",
      "Extraction patche: 146000 / 400000\n",
      "Extraction patche: 147000 / 400000\n",
      "Extraction patche: 148000 / 400000\n",
      "Extraction patche: 149000 / 400000\n",
      "Extraction patche: 150000 / 400000\n",
      "Extraction patche: 151000 / 400000\n",
      "Extraction patche: 152000 / 400000\n",
      "Extraction patche: 153000 / 400000\n",
      "Extraction patche: 154000 / 400000\n",
      "Extraction patche: 155000 / 400000\n",
      "Extraction patche: 156000 / 400000\n",
      "Extraction patche: 157000 / 400000\n",
      "Extraction patche: 158000 / 400000\n",
      "Extraction patche: 159000 / 400000\n",
      "Extraction patche: 160000 / 400000\n",
      "Extraction patche: 161000 / 400000\n",
      "Extraction patche: 162000 / 400000\n",
      "Extraction patche: 163000 / 400000\n",
      "Extraction patche: 164000 / 400000\n",
      "Extraction patche: 165000 / 400000\n",
      "Extraction patche: 166000 / 400000\n",
      "Extraction patche: 167000 / 400000\n",
      "Extraction patche: 168000 / 400000\n",
      "Extraction patche: 169000 / 400000\n",
      "Extraction patche: 170000 / 400000\n",
      "Extraction patche: 171000 / 400000\n",
      "Extraction patche: 172000 / 400000\n",
      "Extraction patche: 173000 / 400000\n",
      "Extraction patche: 174000 / 400000\n",
      "Extraction patche: 175000 / 400000\n",
      "Extraction patche: 176000 / 400000\n",
      "Extraction patche: 177000 / 400000\n",
      "Extraction patche: 178000 / 400000\n",
      "Extraction patche: 179000 / 400000\n",
      "Extraction patche: 180000 / 400000\n",
      "Extraction patche: 181000 / 400000\n",
      "Extraction patche: 182000 / 400000\n",
      "Extraction patche: 183000 / 400000\n",
      "Extraction patche: 184000 / 400000\n",
      "Extraction patche: 185000 / 400000\n",
      "Extraction patche: 186000 / 400000\n",
      "Extraction patche: 187000 / 400000\n",
      "Extraction patche: 188000 / 400000\n",
      "Extraction patche: 189000 / 400000\n",
      "Extraction patche: 190000 / 400000\n",
      "Extraction patche: 191000 / 400000\n",
      "Extraction patche: 192000 / 400000\n",
      "Extraction patche: 193000 / 400000\n",
      "Extraction patche: 194000 / 400000\n",
      "Extraction patche: 195000 / 400000\n",
      "Extraction patche: 196000 / 400000\n",
      "Extraction patche: 197000 / 400000\n",
      "Extraction patche: 198000 / 400000\n",
      "Extraction patche: 199000 / 400000\n",
      "Extraction patche: 200000 / 400000\n",
      "Extraction patche: 201000 / 400000\n",
      "Extraction patche: 202000 / 400000\n",
      "Extraction patche: 203000 / 400000\n",
      "Extraction patche: 204000 / 400000\n",
      "Extraction patche: 205000 / 400000\n",
      "Extraction patche: 206000 / 400000\n",
      "Extraction patche: 207000 / 400000\n",
      "Extraction patche: 208000 / 400000\n",
      "Extraction patche: 209000 / 400000\n",
      "Extraction patche: 210000 / 400000\n",
      "Extraction patche: 211000 / 400000\n",
      "Extraction patche: 212000 / 400000\n",
      "Extraction patche: 213000 / 400000\n",
      "Extraction patche: 214000 / 400000\n",
      "Extraction patche: 215000 / 400000\n",
      "Extraction patche: 216000 / 400000\n",
      "Extraction patche: 217000 / 400000\n",
      "Extraction patche: 218000 / 400000\n",
      "Extraction patche: 219000 / 400000\n",
      "Extraction patche: 220000 / 400000\n",
      "Extraction patche: 221000 / 400000\n",
      "Extraction patche: 222000 / 400000\n",
      "Extraction patche: 223000 / 400000\n",
      "Extraction patche: 224000 / 400000\n",
      "Extraction patche: 225000 / 400000\n",
      "Extraction patche: 226000 / 400000\n",
      "Extraction patche: 227000 / 400000\n",
      "Extraction patche: 228000 / 400000\n",
      "Extraction patche: 229000 / 400000\n",
      "Extraction patche: 230000 / 400000\n",
      "Extraction patche: 231000 / 400000\n",
      "Extraction patche: 232000 / 400000\n",
      "Extraction patche: 233000 / 400000\n",
      "Extraction patche: 234000 / 400000\n",
      "Extraction patche: 235000 / 400000\n",
      "Extraction patche: 236000 / 400000\n",
      "Extraction patche: 237000 / 400000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction patche: 238000 / 400000\n",
      "Extraction patche: 239000 / 400000\n",
      "Extraction patche: 240000 / 400000\n",
      "Extraction patche: 241000 / 400000\n",
      "Extraction patche: 242000 / 400000\n",
      "Extraction patche: 243000 / 400000\n",
      "Extraction patche: 244000 / 400000\n",
      "Extraction patche: 245000 / 400000\n",
      "Extraction patche: 246000 / 400000\n",
      "Extraction patche: 247000 / 400000\n",
      "Extraction patche: 248000 / 400000\n",
      "Extraction patche: 249000 / 400000\n",
      "Extraction patche: 250000 / 400000\n",
      "Extraction patche: 251000 / 400000\n",
      "Extraction patche: 252000 / 400000\n",
      "Extraction patche: 253000 / 400000\n",
      "Extraction patche: 254000 / 400000\n",
      "Extraction patche: 255000 / 400000\n",
      "Extraction patche: 256000 / 400000\n",
      "Extraction patche: 257000 / 400000\n",
      "Extraction patche: 258000 / 400000\n",
      "Extraction patche: 259000 / 400000\n",
      "Extraction patche: 260000 / 400000\n",
      "Extraction patche: 261000 / 400000\n",
      "Extraction patche: 262000 / 400000\n",
      "Extraction patche: 263000 / 400000\n",
      "Extraction patche: 264000 / 400000\n",
      "Extraction patche: 265000 / 400000\n",
      "Extraction patche: 266000 / 400000\n",
      "Extraction patche: 267000 / 400000\n",
      "Extraction patche: 268000 / 400000\n",
      "Extraction patche: 269000 / 400000\n",
      "Extraction patche: 270000 / 400000\n",
      "Extraction patche: 271000 / 400000\n",
      "Extraction patche: 272000 / 400000\n",
      "Extraction patche: 273000 / 400000\n",
      "Extraction patche: 274000 / 400000\n",
      "Extraction patche: 275000 / 400000\n",
      "Extraction patche: 276000 / 400000\n",
      "Extraction patche: 277000 / 400000\n",
      "Extraction patche: 278000 / 400000\n",
      "Extraction patche: 279000 / 400000\n",
      "Extraction patche: 280000 / 400000\n",
      "Extraction patche: 281000 / 400000\n",
      "Extraction patche: 282000 / 400000\n",
      "Extraction patche: 283000 / 400000\n",
      "Extraction patche: 284000 / 400000\n",
      "Extraction patche: 285000 / 400000\n",
      "Extraction patche: 286000 / 400000\n",
      "Extraction patche: 287000 / 400000\n",
      "Extraction patche: 288000 / 400000\n",
      "Extraction patche: 289000 / 400000\n",
      "Extraction patche: 290000 / 400000\n",
      "Extraction patche: 291000 / 400000\n",
      "Extraction patche: 292000 / 400000\n",
      "Extraction patche: 293000 / 400000\n",
      "Extraction patche: 294000 / 400000\n",
      "Extraction patche: 295000 / 400000\n",
      "Extraction patche: 296000 / 400000\n",
      "Extraction patche: 297000 / 400000\n",
      "Extraction patche: 298000 / 400000\n",
      "Extraction patche: 299000 / 400000\n",
      "Extraction patche: 300000 / 400000\n",
      "Extraction patche: 301000 / 400000\n",
      "Extraction patche: 302000 / 400000\n",
      "Extraction patche: 303000 / 400000\n",
      "Extraction patche: 304000 / 400000\n",
      "Extraction patche: 305000 / 400000\n",
      "Extraction patche: 306000 / 400000\n",
      "Extraction patche: 307000 / 400000\n",
      "Extraction patche: 308000 / 400000\n",
      "Extraction patche: 309000 / 400000\n",
      "Extraction patche: 310000 / 400000\n",
      "Extraction patche: 311000 / 400000\n",
      "Extraction patche: 312000 / 400000\n",
      "Extraction patche: 313000 / 400000\n",
      "Extraction patche: 314000 / 400000\n",
      "Extraction patche: 315000 / 400000\n",
      "Extraction patche: 316000 / 400000\n",
      "Extraction patche: 317000 / 400000\n",
      "Extraction patche: 318000 / 400000\n",
      "Extraction patche: 319000 / 400000\n",
      "Extraction patche: 320000 / 400000\n",
      "Extraction patche: 321000 / 400000\n",
      "Extraction patche: 322000 / 400000\n",
      "Extraction patche: 323000 / 400000\n",
      "Extraction patche: 324000 / 400000\n",
      "Extraction patche: 325000 / 400000\n",
      "Extraction patche: 326000 / 400000\n",
      "Extraction patche: 327000 / 400000\n",
      "Extraction patche: 328000 / 400000\n",
      "Extraction patche: 329000 / 400000\n",
      "Extraction patche: 330000 / 400000\n",
      "Extraction patche: 331000 / 400000\n",
      "Extraction patche: 332000 / 400000\n",
      "Extraction patche: 333000 / 400000\n",
      "Extraction patche: 334000 / 400000\n",
      "Extraction patche: 335000 / 400000\n",
      "Extraction patche: 336000 / 400000\n",
      "Extraction patche: 337000 / 400000\n",
      "Extraction patche: 338000 / 400000\n",
      "Extraction patche: 339000 / 400000\n",
      "Extraction patche: 340000 / 400000\n",
      "Extraction patche: 341000 / 400000\n",
      "Extraction patche: 342000 / 400000\n",
      "Extraction patche: 343000 / 400000\n",
      "Extraction patche: 344000 / 400000\n",
      "Extraction patche: 345000 / 400000\n",
      "Extraction patche: 346000 / 400000\n",
      "Extraction patche: 347000 / 400000\n",
      "Extraction patche: 348000 / 400000\n",
      "Extraction patche: 349000 / 400000\n",
      "Extraction patche: 350000 / 400000\n",
      "Extraction patche: 351000 / 400000\n",
      "Extraction patche: 352000 / 400000\n",
      "Extraction patche: 353000 / 400000\n",
      "Extraction patche: 354000 / 400000\n",
      "Extraction patche: 355000 / 400000\n",
      "Extraction patche: 356000 / 400000\n",
      "Extraction patche: 357000 / 400000\n",
      "Extraction patche: 358000 / 400000\n",
      "Extraction patche: 359000 / 400000\n",
      "Extraction patche: 360000 / 400000\n",
      "Extraction patche: 361000 / 400000\n",
      "Extraction patche: 362000 / 400000\n",
      "Extraction patche: 363000 / 400000\n",
      "Extraction patche: 364000 / 400000\n",
      "Extraction patche: 365000 / 400000\n",
      "Extraction patche: 366000 / 400000\n",
      "Extraction patche: 367000 / 400000\n",
      "Extraction patche: 368000 / 400000\n",
      "Extraction patche: 369000 / 400000\n",
      "Extraction patche: 370000 / 400000\n",
      "Extraction patche: 371000 / 400000\n",
      "Extraction patche: 372000 / 400000\n",
      "Extraction patche: 373000 / 400000\n",
      "Extraction patche: 374000 / 400000\n",
      "Extraction patche: 375000 / 400000\n",
      "Extraction patche: 376000 / 400000\n",
      "Extraction patche: 377000 / 400000\n",
      "Extraction patche: 378000 / 400000\n",
      "Extraction patche: 379000 / 400000\n",
      "Extraction patche: 380000 / 400000\n",
      "Extraction patche: 381000 / 400000\n",
      "Extraction patche: 382000 / 400000\n",
      "Extraction patche: 383000 / 400000\n",
      "Extraction patche: 384000 / 400000\n",
      "Extraction patche: 385000 / 400000\n",
      "Extraction patche: 386000 / 400000\n",
      "Extraction patche: 387000 / 400000\n",
      "Extraction patche: 388000 / 400000\n",
      "Extraction patche: 389000 / 400000\n",
      "Extraction patche: 390000 / 400000\n",
      "Extraction patche: 391000 / 400000\n",
      "Extraction patche: 392000 / 400000\n",
      "Extraction patche: 393000 / 400000\n",
      "Extraction patche: 394000 / 400000\n",
      "Extraction patche: 395000 / 400000\n",
      "Extraction patche: 396000 / 400000\n",
      "Extraction patche: 397000 / 400000\n",
      "Extraction patche: 398000 / 400000\n",
      "Extraction patche: 399000 / 400000\n",
      "[-0.95719183 -0.82086258 -0.35013437  0.41575771  1.11030337  1.18610542\n",
      " -1.02704126 -0.6908568  -0.22147998  0.85979165  1.3214031   1.31543245\n",
      " -1.12985706 -0.54351131  0.42456349  0.95584134  1.65068639  2.11139931\n",
      " -0.43118547 -0.14490118  0.45526836  0.66833666  1.28042948  1.77602765\n",
      "  1.51737224  0.66984114  0.60564698  0.8185785   1.54536005  1.92531923\n",
      "  1.74961611  0.60355968  0.37195169  0.60228655  1.57995611  1.87493559\n",
      " -1.39642787 -1.24096115 -1.01685756 -0.4480543   0.31554534  0.56032354\n",
      " -1.32959864 -1.13997849 -0.83327919  0.18536366  0.76720309  0.91441793\n",
      " -1.33041382 -0.95641373 -0.25069227  0.16855573  1.08439979  1.88193475\n",
      " -1.16495869 -0.90701402 -0.36828178 -0.08326314  0.73329532  1.48189635\n",
      " -0.05126541 -0.62744515 -0.31955675  0.18241014  0.99718105  1.41419682\n",
      " -0.00368626 -0.72930253 -0.55544854 -0.13658534  0.96293849  1.41281379\n",
      " -1.42600727 -1.39973386 -1.3556281  -1.23351254 -0.91517506 -0.63245773\n",
      " -1.42686634 -1.33338877 -1.13997339 -0.3350252   0.03426342  0.13582684\n",
      " -1.39543678 -1.1675019  -0.69176112 -0.46939236  0.43338763  1.35201305\n",
      " -1.44719189 -1.23547804 -0.82656479 -0.75514759  0.04829645  0.90148009\n",
      " -0.76714504 -1.122929   -0.74490469 -0.40644649  0.22883252  0.55089685\n",
      " -0.66957555 -1.05873517 -1.03210147 -0.67614229  0.31122649  0.41625955]\n"
     ]
    }
   ],
   "source": [
    "#create unsurpervised data\n",
    "import numpy as np\n",
    "patches=[]\n",
    "rfSize = 6\n",
    "numCentroids=100\n",
    "whitening=True\n",
    "numPatches = 400000\n",
    "CIFAR_DIM=[32,32,3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patches= np.zeros((numPatches, rfSize*rfSize*3))\n",
    "for i in range(0, numPatches):\n",
    "    if i%1000==0:\n",
    "        print('Extraction patche:', i, '/', numPatches)\n",
    "    r= np.random.randint(CIFAR_DIM[0]-rfSize) \n",
    "    c= np.random.randint(CIFAR_DIM[0]-rfSize)\n",
    "    patch= (X_train[(i%len(X_train)),:])  \n",
    "    \n",
    "    #print(patch.shape)#.reshape(32,32,3)\n",
    "    patch= patch[:,r:r+rfSize, c:c+rfSize]\n",
    "    \n",
    "    #print(patch.shape)\n",
    "    #print((patch.reshape(1,-1)).shape)\n",
    "    patches[i]=(patch.reshape(1,-1))\n",
    "patches=(patches-patches.mean(1)[:,None])/np.sqrt(patches.var(1)+10)[:,None]\n",
    "\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "#patches = preprocessing.normalize(patches, norm='l2')\n",
    "\n",
    "#Normlize\n",
    "print(patches[0])\n",
    "[D,V]=np.linalg.eig(np.cov(patches,rowvar=0))\n",
    "\n",
    "P = V.dot(np.diag(np.sqrt(1/(D + 0.1)))).dot(V.T)\n",
    "patches = patches.dot(P)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "(25, 108)\n"
     ]
    }
   ],
   "source": [
    "## We can also use the run_kmeans I have code below \n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=25, n_init=5, max_iter=100, init_size=300, batch_size=1000).fit(patches)\n",
    "Nrep= kmeans.cluster_centers_\n",
    "NrepL= list(Nrep)\n",
    "print(len(Nrep))\n",
    "array= np.array(Nrep)\n",
    "centroids=array\n",
    "print(array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def run_kmeans(X,k,iterations):\n",
    "    x2= np.sum(np.power(X,2), axis=1)\n",
    "   \n",
    "    centroids= np.random.randn(k, np.size(X,1))*0.1\n",
    "    \n",
    "    BATCH_SIZE=1000\n",
    "    \n",
    "    for itr in range(1,iterations+1):\n",
    "        print('kmeans iteration ', itr ,'/', iterations)\n",
    "        c2= 0.5*np.sum(np.power(centroids,2), axis=1)\n",
    "        summation= np.zeros((k, np.size(X,1))) # len(X[0][:])\n",
    "        #counts= np.zeros((k,1))\n",
    "        count1=[]\n",
    "        loss=0\n",
    "        c=0\n",
    "        for i in range(1,len(X), BATCH_SIZE ):\n",
    "            lastindex=min(i+BATCH_SIZE-1, len(X))\n",
    "            #print(lastindex)\n",
    "            m= lastindex -i +1 \n",
    "            #print(m)\n",
    "            batch= X[i-1:lastindex ,:]   #batch= X[i:lastindex+1 ,:]\n",
    "            batch_t=batch.transpose()\n",
    "            tmp= centroids.dot(batch_t)\n",
    "            for n in range(1, len(batch)):\n",
    "                tmp[:,n]=tmp[:,n]-c2\n",
    "                \n",
    "            val=[]\n",
    "            labels=[]\n",
    "            [val ,labels] = [np.max(tmp, axis=0),np.argmax(tmp, axis=0) ]   \n",
    "            \n",
    "            loss= loss + np.sum(0.5*x2[i-1:lastindex]-val.transpose())\n",
    "            #print(len(labels))\n",
    "            #print(np.max(labels))\n",
    "            \n",
    "            # tranformer label en matrice indicatrice\n",
    "            S=np.zeros((m,k))\n",
    "            #print(len(labels))\n",
    "            #print(lastindex-1-i)\n",
    "            for j in range(1, lastindex-i):\n",
    "                S[j][labels[j]]=1\n",
    "            #print(np.shape(S.transpose()))\n",
    "            #print(np.shape(X[i:lastindex+1,:]))\n",
    "            \n",
    "            summation = summation+(S.transpose()).dot(X[i-1:lastindex,:])\n",
    "            counts= (np.sum(S,axis=0).transpose())\n",
    "            count1.append(counts)\n",
    "            #print(np.shape(counts))\n",
    "            #print(np.shape(summation))\n",
    "            c=c+1\n",
    "            #print(c)\n",
    "            #normalize\n",
    "        counts=np.sum(np.array(count1),axis=0)\n",
    "        #print(np.shape(np.sum(S,axis=0).transpose()))\n",
    "       # print(np.shape(counts))\n",
    "        #print(np.shape(summation))    \n",
    "            #centroids = summation/counts\n",
    "        for i in range(1, k):\n",
    "            \n",
    "            if counts[i].all!=0:\n",
    "                centroids[i]=summation[i,:]/counts[i]\n",
    "            elif counts[i]==0:\n",
    "                centroids[i]=centroids[i]*0\n",
    "                    \n",
    "            \n",
    "        badIndex= [i for i,val in enumerate(counts) if val.any()==0]\n",
    "        centroids[badIndex,:]=0     \n",
    "            \n",
    "    return centroids, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans iteration  1 / 100\n",
      "kmeans iteration  2 / 100\n",
      "kmeans iteration  3 / 100\n",
      "kmeans iteration  4 / 100\n",
      "kmeans iteration  5 / 100\n",
      "kmeans iteration  6 / 100\n",
      "kmeans iteration  7 / 100\n",
      "kmeans iteration  8 / 100\n",
      "kmeans iteration  9 / 100\n",
      "kmeans iteration  10 / 100\n",
      "kmeans iteration  11 / 100\n",
      "kmeans iteration  12 / 100\n",
      "kmeans iteration  13 / 100\n",
      "kmeans iteration  14 / 100\n",
      "kmeans iteration  15 / 100\n",
      "kmeans iteration  16 / 100\n",
      "kmeans iteration  17 / 100\n",
      "kmeans iteration  18 / 100\n",
      "kmeans iteration  19 / 100\n",
      "kmeans iteration  20 / 100\n",
      "kmeans iteration  21 / 100\n",
      "kmeans iteration  22 / 100\n",
      "kmeans iteration  23 / 100\n",
      "kmeans iteration  24 / 100\n",
      "kmeans iteration  25 / 100\n",
      "kmeans iteration  26 / 100\n",
      "kmeans iteration  27 / 100\n",
      "kmeans iteration  28 / 100\n",
      "kmeans iteration  29 / 100\n",
      "kmeans iteration  30 / 100\n",
      "kmeans iteration  31 / 100\n",
      "kmeans iteration  32 / 100\n",
      "kmeans iteration  33 / 100\n",
      "kmeans iteration  34 / 100\n",
      "kmeans iteration  35 / 100\n",
      "kmeans iteration  36 / 100\n",
      "kmeans iteration  37 / 100\n",
      "kmeans iteration  38 / 100\n",
      "kmeans iteration  39 / 100\n",
      "kmeans iteration  40 / 100\n",
      "kmeans iteration  41 / 100\n",
      "kmeans iteration  42 / 100\n",
      "kmeans iteration  43 / 100\n",
      "kmeans iteration  44 / 100\n",
      "kmeans iteration  45 / 100\n",
      "kmeans iteration  46 / 100\n",
      "kmeans iteration  47 / 100\n",
      "kmeans iteration  48 / 100\n",
      "kmeans iteration  49 / 100\n",
      "kmeans iteration  50 / 100\n",
      "kmeans iteration  51 / 100\n",
      "kmeans iteration  52 / 100\n",
      "kmeans iteration  53 / 100\n",
      "kmeans iteration  54 / 100\n",
      "kmeans iteration  55 / 100\n",
      "kmeans iteration  56 / 100\n",
      "kmeans iteration  57 / 100\n",
      "kmeans iteration  58 / 100\n",
      "kmeans iteration  59 / 100\n",
      "kmeans iteration  60 / 100\n",
      "kmeans iteration  61 / 100\n",
      "kmeans iteration  62 / 100\n",
      "kmeans iteration  63 / 100\n",
      "kmeans iteration  64 / 100\n",
      "kmeans iteration  65 / 100\n",
      "kmeans iteration  66 / 100\n",
      "kmeans iteration  67 / 100\n",
      "kmeans iteration  68 / 100\n",
      "kmeans iteration  69 / 100\n",
      "kmeans iteration  70 / 100\n",
      "kmeans iteration  71 / 100\n",
      "kmeans iteration  72 / 100\n",
      "kmeans iteration  73 / 100\n",
      "kmeans iteration  74 / 100\n",
      "kmeans iteration  75 / 100\n",
      "kmeans iteration  76 / 100\n",
      "kmeans iteration  77 / 100\n",
      "kmeans iteration  78 / 100\n",
      "kmeans iteration  79 / 100\n",
      "kmeans iteration  80 / 100\n",
      "kmeans iteration  81 / 100\n",
      "kmeans iteration  82 / 100\n",
      "kmeans iteration  83 / 100\n",
      "kmeans iteration  84 / 100\n",
      "kmeans iteration  85 / 100\n",
      "kmeans iteration  86 / 100\n",
      "kmeans iteration  87 / 100\n",
      "kmeans iteration  88 / 100\n",
      "kmeans iteration  89 / 100\n",
      "kmeans iteration  90 / 100\n",
      "kmeans iteration  91 / 100\n",
      "kmeans iteration  92 / 100\n",
      "kmeans iteration  93 / 100\n",
      "kmeans iteration  94 / 100\n",
      "kmeans iteration  95 / 100\n",
      "kmeans iteration  96 / 100\n",
      "kmeans iteration  97 / 100\n",
      "kmeans iteration  98 / 100\n",
      "kmeans iteration  99 / 100\n",
      "kmeans iteration  100 / 100\n"
     ]
    }
   ],
   "source": [
    "centroids=run_kmeans(patches,numCentroids,100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids= np.array(centroids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function Im2col allows to find overllaping patch\n",
    "\n",
    "def im2col_sliding_broadcasting(A, BSZ, stepsize=1):\n",
    "    # Parameters\n",
    "    M,N = A.shape\n",
    "    col_extent = N - BSZ[1] + 1\n",
    "    row_extent = M - BSZ[0] + 1\n",
    "\n",
    "    # Get Starting block indices\n",
    "    start_idx = np.arange(BSZ[0])[:,None]*N + np.arange(BSZ[1])\n",
    "\n",
    "    # Get offsetted indices across the height and width of input array\n",
    "    offset_idx = np.arange(row_extent)[:,None]*N + np.arange(col_extent)\n",
    "\n",
    "    # Get all actual indices & index into input array for final output\n",
    "    return np.take (A,start_idx.ravel()[:,None] + offset_idx.ravel()[::stepsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import distance\n",
    "#XC = np.zeros((50000,4*100))\n",
    "def extract_features (X):\n",
    "    whitening = True #(nargin==6)\n",
    "    trainXC=[]\n",
    "    liste=[]\n",
    "    for i in range(0, len(X)):\n",
    "        if (i%1000==0):\n",
    "            print('Extraction features: ')#+i+ '/'+ len(X))\n",
    "            \n",
    "        #shape de patches (729,108)    \n",
    "        patches =np.concatenate([im2col_sliding_broadcasting((X[i].reshape(-1,1)[0:1024]).reshape(32,32) , [6,6], stepsize=1)\n",
    "        ,im2col_sliding_broadcasting((X[i].reshape(-1,1)[1024:2048]).reshape(32,32), [6,6], stepsize=1),\n",
    "        im2col_sliding_broadcasting((X[i].reshape(-1,1)[2048:]).reshape(32,32),[ 6,6], stepsize=1) ], axis=0)\n",
    "        patches=patches.transpose()\n",
    "        \n",
    "        patches=np.array(patches)\n",
    "        \n",
    "        \n",
    "        patches=(patches-patches.mean(1)[:,None])/(np.sqrt(patches.var(1)+10)[:,None])\n",
    "        #map to feature space\n",
    "        patches=patches.dot(P)\n",
    "        #calculate distance using x2-2xc+c2\n",
    "        x2=np.power(patches,2).sum(1)\n",
    "        c2=np.power(centroids,2).sum(1)\n",
    "        xc=patches.dot(centroids.T)\n",
    "        dist=np.sqrt(-2*xc+x2[:,None]+c2)\n",
    "        \n",
    "       #patches.dot(P) si matrice\n",
    "      \n",
    "        \n",
    "        \n",
    "        z =dist # 13h          \n",
    "      \n",
    "        \n",
    "        u=dist.mean(1)\n",
    "        patches=np.maximum(-dist+u[:,None],0)\n",
    "        rs=CIFAR_DIM[0]-rfSize+1\n",
    "        cs=CIFAR_DIM[1]-rfSize+1\n",
    "        patches=np.reshape(patches,[rs,cs,-1])\n",
    "        q=[]\n",
    "        q.append(patches[0:int(rs/2)+1,0:int(cs/2)+1].sum(0).sum(0))\n",
    "        q.append(patches[0:int(rs/2)+1,int(cs/2)+1:cs-1].sum(0).sum(0))\n",
    "        q.append(patches[int(rs/2)+1:rs-1,0:int(cs/2)+1].sum(0).sum(0))\n",
    "        q.append(patches[int(rs/2)+1:rs-1,int(cs/2)+1:cs-1].sum(0).sum(0))\n",
    "        q=np.array(q).ravel()\n",
    "        trainXC.append(q)\n",
    "    trainXC=np.array(trainXC)\n",
    "    trainXC=(trainXC-trainXC.mean(1)[:,None])/(np.sqrt(trainXC.var(1)+.01)[:,None])\n",
    "    return trainXC\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "Extraction features: \n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "### Calcul of features , with matrices distances ,take distance < mean(distance) + pooling patches\n",
    "\n",
    "#Extract features of Xtrain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A=extract_features (X_train )\n",
    "\n",
    "print(np.shape(A[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 400)\n",
      "Extraction features: \n"
     ]
    }
   ],
   "source": [
    "#Extract features of X_test \n",
    "print(A.shape)\n",
    "\n",
    "BBB=extract_features (X_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train svm classifier \n",
    "tabLoss=[]\n",
    "import numpy as np\n",
    "def my_l2svmloss(w, *args):\n",
    "    #print(len(args))\n",
    "    X=args[0]\n",
    "    y=args[1]\n",
    "    K=args[2]\n",
    "    C=args[3]\n",
    "    [M,N]= np.shape(X)   \n",
    "    theta= w.reshape(N,K)  \n",
    "    Y= np.zeros((len(y),K))   \n",
    "    for i in range(0, len(y)):\n",
    "        for k in range(1, K+1):\n",
    "            if y[i]==k:\n",
    "                Y[i,k-1]=Y[i,k-1]+1       \n",
    "            else: Y[i,k-1]=Y[i,k-1]-1\n",
    "\n",
    "    margin = np.maximum(0, 1-Y*(X.dot(theta)))    \n",
    "  \n",
    "    loss= (0.5* np.sum((np.power(theta,2)), axis=0))+ C*np.mean((np.power(margin,2)), axis=0)\n",
    "  \n",
    "    loss= np.sum(loss, axis=0) \n",
    "    tabLoss.append(loss)\n",
    "    g = theta -2*C/M*(X.transpose().dot(margin*Y))\n",
    "    g.reshape(np.size(X, 1)*K,1)\n",
    "  \n",
    "    return loss, np.hstack(g)\n",
    "\n",
    "#objectif mininimiser loss et g \n",
    "\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "def train_svm(trainXC, trainY, C):\n",
    "    X= trainXC   #featurize data \n",
    "    y= trainY   \n",
    "    \n",
    "    K = np.max(trainY)  #number of classes \n",
    "    \n",
    "    w0= np.zeros((np.size(X, 1)*K,1) )# 10* (4*numcentroids+1) , w vector of weight for the 10 classes \n",
    "    w0=np.array(w0)\n",
    "    #minimize the function svmloss\n",
    "    w, fw ,i   = fmin_l_bfgs_b(my_l2svmloss,w0,args =([X,y,K,C  ]), maxfun=1000, maxiter=1000)  #x,f,d   / w, fw, i\n",
    "   \n",
    "    theta= w.reshape(np.size(trainXC, 1), K )\n",
    "    return theta ,i\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "import numpy as np\n",
    "#Asc = preprocessing.scale(A)\n",
    "\n",
    "#Standardize the data \n",
    "Asc= A- np.mean(A,axis=0)\n",
    "Asc= Asc/np.sqrt(np.var(A,axis=0)+0.01)\n",
    "One= np.array([1]*49000)\n",
    "\n",
    "Asc=np.c_[ Asc, np.ones(len(A)) ] \n",
    "\n",
    "#train SVM with with the features of A (features from Xtrain) standardised , and Y_train=Cifar[1]+1\n",
    "\n",
    "theta=train_svm(Asc, y_train+1 , 100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train result :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6600204081632653"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we find with f_min the function who find w  who minimize the fonction svmloss\n",
    "\n",
    "Matrice = Asc.dot(theta)      #theta= w  theta shape : (4* num Centroids, number of class ), Asc= x ,\n",
    "#Asc.shape = 50000, 4*numCentroids, Matrice (50000, 10) argamx axis= 1 sort the number of the class predict \n",
    "#higher score with weight vector \n",
    "[val1 ,inds1] = [np.max(Matrice, axis=1),np.argmax(Matrice, axis=1) ]  #y_pred= argmax(x*wy)\n",
    "print('train result :')\n",
    "(inds1==y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data of X_test with the data X_train\n",
    "reserve=BBB\n",
    "BBB=BBB- np.mean(A,axis=0)\n",
    "BBB= BBB/ np.sqrt(np.var(A,axis=0)+0.01)\n",
    "Bsc=np.c_[ BBB, np.ones(len(BBB)) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuraccy result on Xtest:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.634"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MatriceTest= Bsc.dot(theta)\n",
    "[val2 ,inds2] = [np.max(MatriceTest, axis=1),np.argmax(MatriceTest, axis=1) ]\n",
    "print('Accuraccy result on Xtest:')\n",
    "(inds2==y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction features: \n",
      "Accuraccy result on Xtest:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.646"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=extract_features (X_test )\n",
    "test=test- np.mean(A,axis=0)\n",
    "test= test/ np.sqrt(np.var(A,axis=0)+0.01)\n",
    "Tsc=np.c_[test, np.ones(len(test)) ] \n",
    "MatriceTest1= Tsc.dot(theta)\n",
    "[val3 ,inds3] = [np.max(MatriceTest1, axis=1),np.argmax(MatriceTest1, axis=1) ]\n",
    "print('Accuraccy result on Xtest:')\n",
    "(inds3==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "plt.plot(tabLoss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictio=train_svm(Asc, y_train+1 , 100)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tabLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "%matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test = y_test\n",
    "y_pred = inds3\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['airplane', 'automobile', 'bird', 'cat', 'deer' ,'dog', 'frog', 'horse' ,'ship' ,'truck'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['airplane', 'automobile', 'bird', 'cat', 'deer' ,'dog', 'frog', 'horse' ,'ship' ,'truck'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = A.shape[1]\n",
    "hidden_size = 200\n",
    "num_classes = 10\n",
    "\n",
    "Asc1= A- np.mean(A,axis=0)\n",
    "Asc1= Asc1/np.sqrt(np.var(A,axis=0)+0.01)\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes,1e-4)\n",
    "stats = net.train(Asc1, Cifar[1] , BBB, Cifar[3] ,\n",
    "                            num_iters=70000, batch_size=128,\n",
    "                            learning_rate=5e-4, learning_rate_decay=0.99,\n",
    "                            reg=0, verbose=True,update=\"SGD\",arg=0.95,dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = (net.predict(Asc1) == Cifar[1]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288.94487380762916"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabLoss[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout , Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import sklearn.preprocessing\n",
    "from keras.optimizers import SGD\n",
    "#optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon = 1e-06, decay=1e-6)\n",
    "\n",
    "a=y_train\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(max(a)+1))\n",
    "C1=label_binarizer.transform(a)\n",
    "b=y_val\n",
    "C2=label_binarizer.transform(b)\n",
    "model= Sequential()\n",
    "model.add(Dense(50,input_shape=(A.shape[1],)))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon = 1e-06, decay=1e-6), metrics=['accuracy'])\n",
    "history = model.fit(A, C1 , batch_size=1000, epochs=1000, verbose=2, validation_split=0.2)\n",
    "loss_and_metrics= model.evaluate(BBB, C2)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
